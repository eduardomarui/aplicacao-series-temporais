
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from datetime import datetime, timedelta, timedelta
import random

# Definir seeds para reprodutibilidade
seed = 42
torch.manual_seed(seed)
torch.cuda.manual_seed_all(seed) if torch.cuda.is_available() else None
np.random.seed(seed)
random.seed(seed)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# 1. Defini√ß√£o da arquitetura TCN
# ------------------------------------------------------------------
# A TCN √© uma alternativa moderna √†s RNNs/LSTMs que usa convolu√ß√µes
# dilatadas para capturar depend√™ncias temporais de longo prazo
class TemporalBlock(nn.Module):
    """
    Bloco temporal b√°sico da TCN.
    
    Implementa duas camadas convolucionais 1D com:
    - Dilata√ß√£o para capturar depend√™ncias de longo prazo
    - Padding causal (n√£o v√™ o futuro) 
    - Conex√µes residuais para evitar vanishing gradient
    - Dropout para regulariza√ß√£o
    """
    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):
        super(TemporalBlock, self).__init__()
        
        # Primeira camada convolucional com dilata√ß√£o
        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size,
                               stride=stride, padding=padding, dilation=dilation)
        self.chomp1 = Chomp1d(padding)  # Remove padding extra para manter causalidade
        self.relu1 = nn.ReLU()
        self.dropout1 = nn.Dropout(dropout)

        # Segunda camada convolucional (mesmo padr√£o)
        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size,
                               stride=stride, padding=padding, dilation=dilation)
        self.chomp2 = Chomp1d(padding)
        self.relu2 = nn.ReLU()
        self.dropout2 = nn.Dropout(dropout)

        # Sequ√™ncia completa das opera√ß√µes
        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,
                                 self.conv2, self.chomp2, self.relu2, self.dropout2)
        
        # Conex√£o residual (adapta dimens√µes se necess√°rio)
        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None
        self.relu = nn.ReLU()

    def forward(self, x):
        """
        Forward pass com conex√£o residual.
        out = ReLU(F(x) + x) onde F(x) √© a transforma√ß√£o convolucional
        """
        out = self.net(x)
        res = x if self.downsample is None else self.downsample(x)
        return self.relu(out + res)  # Conex√£o residual + ativa√ß√£o final

class Chomp1d(nn.Module):
    """
    Remove padding do final da sequ√™ncia para manter causalidade.
    
    A TCN usa padding para manter o tamanho da sequ√™ncia, mas precisa
    remover o padding do final para garantir que n√£o "veja o futuro".
    """
    def __init__(self, chomp_size):
        super(Chomp1d, self).__init__()
        self.chomp_size = chomp_size

    def forward(self, x):
        # Remove chomp_size elementos do final da dimens√£o temporal
        return x[:, :, :-self.chomp_size].contiguous()

class TemporalConvNet(nn.Module):
    """
    Rede Convolucional Temporal completa.
    
    Empilha m√∫ltiplos TemporalBlocks com dilata√ß√£o exponencial:
    - Camada 1: dilata√ß√£o = 1 (v√™ 1 passo)
    - Camada 2: dilata√ß√£o = 2 (v√™ 2 passos)  
    - Camada 3: dilata√ß√£o = 4 (v√™ 4 passos)
    
    Isso permite capturar depend√™ncias de diferentes escalas temporais.
    """
    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):
        super(TemporalConvNet, self).__init__()
        layers = []
        num_levels = len(num_channels)
        
        for i in range(num_levels):
            dilation_size = 2 ** i  # Dilata√ß√£o exponencial: 1, 2, 4, 8...
            in_channels = num_inputs if i == 0 else num_channels[i-1]
            out_channels = num_channels[i]
            
            # Adiciona um TemporalBlock com dilata√ß√£o espec√≠fica
            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, 
                                   dilation=dilation_size,
                                   padding=(kernel_size-1) * dilation_size, dropout=dropout)]

        self.network = nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

class TCN(nn.Module):
    """
    Modelo TCN completo para previs√£o de s√©ries temporais.
    
    Combina a rede convolucional temporal com uma camada linear final
    para produzir a previs√£o escalar (pre√ßo futuro).
    """
    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):
        super(TCN, self).__init__()
        # Rede convolucional temporal (extrai features temporais)
        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout=dropout)
        # Camada linear final (converte features em previs√£o)
        self.linear = nn.Linear(num_channels[-1], output_size)

    def forward(self, x):
        # Passa pela TCN e pega apenas o √∫ltimo timestep
        output = self.tcn(x)
        # Aplica camada linear ao √∫ltimo timestep para obter previs√£o
        output = self.linear(output[:, :, -1])
        return output

# 2. Fun√ß√£o para criar sequ√™ncias de dados
# ------------------------------------------------------------------
def create_sequences(data, seq_length, forecast_horizon):
    """
    Cria sequ√™ncias de entrada e sa√≠da para treinar a TCN.
    
    Par√¢metros:
    - data: s√©rie temporal normalizada
    - seq_length: tamanho da janela de observa√ß√£o (10 dias)
    - forecast_horizon: horizonte de previs√£o (3 dias √† frente)
    
    Retorna:
    - sequences: janelas de seq_length dias 
    - targets: valores 3 dias √† frente de cada janela
    
    Exemplo: se seq_length=10 e forecast_horizon=3:
    - Entrada: dias [1,2,3,4,5,6,7,8,9,10]
    - Sa√≠da: dia 13 (10 + 3)
    """
    sequences = []
    targets = []
    for i in range(len(data) - seq_length - forecast_horizon + 1):
        seq = data[i:i + seq_length]  # janela de observa√ß√£o
        target = data[i + seq_length + forecast_horizon - 1]  # 3 dias √† frente
        sequences.append(seq)
        targets.append(target)
    return np.array(sequences), np.array(targets)

# 3. Leitura e pr√©-processamento dos dados (mesmo que ARIMA)
# ------------------------------------------------------------------
# Carrega dados hist√≥ricos das empresas exportados do investing.com

# Lista de empresas a analisar
empresas = ['PETR4', 'RECV3', 'WEG3']

# Mapeamento de arquivos CSV para cada empresa
arquivos_csv = {
    'PETR4': 'PETR4 Dados Hist√≥ricos (1).csv',
    'RECV3': 'RECV3 Dados HistoÃÅricos - coÃÅpia.csv',
    'WEG3': 'WEGE3 Dados Hist√≥ricos (3).csv'  # Corrigido
}

# Loop sobre cada empresa
for empresa in empresas:
    print(f"\nüè¢ Analisando empresa: {empresa}")
    print("=" * 80)
    
    # Carregar dados da empresa atual
    df = pd.read_csv(arquivos_csv[empresa], delimiter=',', encoding='utf-8')
    
    # Converte coluna '√öltimo' (pre√ßo de fechamento) de formato brasileiro para float
    # Formato brasileiro: "12.345,67" ‚Üí formato python: 12345.67
    df['Pre√ßo'] = (
        df['√öltimo']
          .str.replace('.', '', regex=False)   # remove separador de milhares (.)
          .str.replace(',', '.', regex=False)  # converte v√≠rgula decimal (,) para ponto (.)
          .astype(float)
    )
    
    # Inverte ordem dos dados: mais antigo (√≠ndice 0) ‚Üí mais recente (√≠ndice -1)
    # Necess√°rio porque dados do investing.com v√™m do mais recente para o mais antigo
    serie = df['Pre√ßo'].values[::-1][-360:]  # √öltimos 360 dias
    n = len(serie)
    
    # 4. Divis√£o treino/teste (mesmo que ARIMA)
    # ------------------------------------------------------------------
    # Usa mesma divis√£o 70/30 que o ARIMA para compara√ß√£o justa
    n_train = int(0.7 * n)      # 70% para treino
    train = serie[:n_train]     # dados de treino
    test = serie[n_train:]      # dados de teste
    
    # 5. Normaliza√ß√£o dos dados
    # ------------------------------------------------------------------
    # TCNs s√£o sens√≠veis √† escala dos dados, diferente do ARIMA
    # StandardScaler transforma os dados para m√©dia=0 e desvio=1
    scaler = StandardScaler()
    train_scaled = scaler.fit_transform(train.reshape(-1, 1)).flatten()  # aprende m√©dia/desvio do treino
    test_scaled = scaler.transform(test.reshape(-1, 1)).flatten()        # aplica mesma transforma√ß√£o no teste
    serie_scaled = scaler.transform(serie.reshape(-1, 1)).flatten()      # s√©rie completa normalizada
    
    # 6. Par√¢metros da TCN (equivalentes ao ARIMA)
    # ------------------------------------------------------------------
    # Vamos testar diferentes tamanhos de sequ√™ncia para comparar performance
    seq_lengths_to_test = [3,5,10,15]  # diferentes tamanhos de observa√ß√£o
    h = 3                       # horizonte de previs√£o de 3 dias (mesmo que ARIMA)
    num_channels = [16, 32, 16] # arquitetura da TCN: 3 camadas com 16‚Üí32‚Üí16 filtros
    kernel_size = 3             # tamanho do kernel convolucional (3 pontos temporais)
    dropout = 0.2              # taxa de dropout para regulariza√ß√£o
    learning_rate = 0.01       # taxa de aprendizado (maior para convergir mais r√°pido)
    epochs = 30                # menos √©pocas para ser mais r√°pido nos testes
    
    # 7. Rolling forecast com retraining para diferentes tamanhos de sequ√™ncia
    # ------------------------------------------------------------------
    # Testa diferentes tamanhos de observa√ß√£o: 15, 10, 5 e 3 dias
    import time
    
    print("Testando TCN com diferentes tamanhos de sequ√™ncia...")
    print(f"Tamanhos a testar: {seq_lengths_to_test}")
    print(f"Horizonte de previs√£o: {h} dias")
    print("=" * 80)
    
    # Dicion√°rio para armazenar todos os resultados para a tabela Excel
    all_results = {}
    
    # Loop sobre diferentes tamanhos de sequ√™ncia
    for seq_length in seq_lengths_to_test:
        print(f"\nüîç Testando com seq_length = {seq_length} dias")
        print("-" * 50)
        
        # Resetar hist√≥rico para cada teste
        history_scaled = list(train_scaled)
        predictions_scaled = []
        total_steps = len(test) - h + 1
        
        print(f"Total de passos: {total_steps}")
        print(f"Par√¢metros: seq_length={seq_length}, epochs={epochs}, lr={learning_rate}")
        print("=" * 50)
        
        start_time = time.time()
        
        for t in range(total_steps):
            step_start = time.time()
            print(f"Passo {t+1}/{total_steps} - ", end="", flush=True)
            
            # Criar sequ√™ncias para treino usando apenas dados hist√≥ricos
            current_train = np.array(history_scaled)
            X_train, y_train = create_sequences(current_train, seq_length, h)
            
            # Verifica√ß√£o de seguran√ßa: precisa de amostras suficientes
            if len(X_train) < 5:  # m√≠nimo de 5 amostras
                print("Poucas amostras, pulando...")
                continue
            
            print(f"Treino: {len(X_train)} amostras - ", end="", flush=True)
            
            # Preparar dados para PyTorch (convers√£o de formatos)
            X_train_tensor = torch.FloatTensor(X_train).unsqueeze(-1)  # [batch, seq, features]
            X_train_tensor = X_train_tensor.transpose(1, 2)           # [batch, features, seq] para Conv1d
            y_train_tensor = torch.FloatTensor(y_train)
            
            # Criar e configurar novo modelo TCN para este passo
            model = TCN(input_size=1, output_size=1, num_channels=num_channels, 
                        kernel_size=kernel_size, dropout=dropout)
            criterion = nn.MSELoss()                                   # fun√ß√£o de perda
            optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # otimizador
            
            # Dataset e DataLoader para treinamento em lotes
            dataset = TensorDataset(X_train_tensor, y_train_tensor)
            dataloader = DataLoader(dataset, batch_size=min(32, len(X_train)), shuffle=True)
            
            # Treinamento do modelo
            model.train()
            train_start = time.time()
            for epoch in range(epochs):
                epoch_loss = 0
                for batch_X, batch_y in dataloader:
                    optimizer.zero_grad()                    # zera gradientes
                    output = model(batch_X)                  # forward pass
                    loss = criterion(output, batch_y.unsqueeze(-1))  # output: [batch, 1], target: [batch, 1]
                    loss.backward()                          # backward pass
                    optimizer.step()                         # atualiza pesos
                    epoch_loss += loss.item()
                
                # Mostrar progresso a cada 10 √©pocas
                if (epoch + 1) % 10 == 0:
                    print(f"E{epoch+1}", end="", flush=True)
            
            train_time = time.time() - train_start
            print(f" - Treino: {train_time:.1f}s - ", end="", flush=True)
            
            # Fazer previs√£o 3 dias √† frente
            model.eval()
            with torch.no_grad():
                # Usar os √∫ltimos seq_length pontos do hist√≥rico para prever
                last_sequence = np.array(history_scaled[-seq_length:])
                X_pred = torch.FloatTensor(last_sequence).unsqueeze(0).unsqueeze(-1)
                X_pred = X_pred.transpose(1, 2)
                prediction_scaled = model(X_pred).item()  # obter previs√£o escalar
                predictions_scaled.append(prediction_scaled)
            
            # Incorporar valor real do dia atual ao hist√≥rico (mesmo que ARIMA)
            history_scaled.append(test_scaled[t])
            
            # Calcular estat√≠sticas de tempo e ETA
            step_time = time.time() - step_start
            elapsed_total = time.time() - start_time
            avg_time_per_step = elapsed_total / (t + 1)
            eta = avg_time_per_step * (total_steps - t - 1)
            
            print(f"Passo: {step_time:.1f}s | ETA: {eta/60:.1f}min")
        
        total_time = time.time() - start_time
        print("=" * 50)
        print(f"Tempo total para seq_length={seq_length}: {total_time/60:.1f} minutos")
        
        # 8. Desnormalizar previs√µes
        # ------------------------------------------------------------------
        predictions_scaled = np.array(predictions_scaled)
        predictions = scaler.inverse_transform(predictions_scaled.reshape(-1, 1)).flatten()
        
        # 9. C√°lculo de m√©tricas de erro
        # ------------------------------------------------------------------
        real_vals = test[h-1:]  # valores reais alinhados (3 dias √† frente)
        mae = mean_absolute_error(real_vals, predictions)
        rmse = np.sqrt(mean_squared_error(real_vals, predictions))
        print(f"MAE ({seq_length} dias ‚Üí 3 √† frente):  {mae:.4f}")
        print(f"RMSE ({seq_length} dias ‚Üí 3 √† frente): {rmse:.4f}")
        
        # Armazenar resultados para a tabela Excel
        all_results[seq_length] = {
            'predictions': predictions,
            'real_vals': real_vals,
            'mae': mae,
            'rmse': rmse,
            'total_time': total_time
        }
        
        # 10. Prepara√ß√£o de eixos para plot
        # ------------------------------------------------------------------
        all_x = np.arange(n)
        window = 10  # Mesmo que ARIMA
        hist_x = np.arange(n_train - window, n_train)
        test_x = np.arange(n_train, n_train + len(test))
        fc_x = test_x[h-1:]  # eixo das previs√µes (alinhado 3 dias √† frente)
        
        # 11. GR√ÅFICO 1: APENAS BOLINHAS (estilo ARIMA)
        # ------------------------------------------------------------------
        fig, ax = plt.subplots(figsize=(10,5))
        
        # √öltimos dias de treino para contexto local (azul)
        ax.plot(hist_x, serie[n_train-window:n_train], color='blue', label='√öltimos 10 dias de treino')
        
        # Valores reais 3 dias √† frente (linha com pontos pretos)
        ax.plot(fc_x, real_vals, 'o-', color='black', label='Teste (real)')
        
        # Previs√µes TCN (linha tracejada com pontos coloridos)
        colors = ['red', 'orange', 'green', 'purple']
        color_idx = seq_lengths_to_test.index(seq_length)
        ax.plot(fc_x, predictions, '--o', color=colors[color_idx], label=f'Previs√£o 3 dias √† frente')
        
        # Linha vertical marcando fim do per√≠odo de treino
        ax.axvline(n_train - 0.5, color='gray', linestyle='--', label='Fim do treino')
        
        # Zoom na regi√£o de interesse
        ax.set_xlim(n_train - window, fc_x[-1] + 1)
        
        # Ajuste autom√°tico do eixo Y com margem
        all_plot = np.concatenate([serie[n_train-window:n_train], real_vals, predictions])
        ymin, ymax = all_plot.min(), all_plot.max()
        marg = (ymax - ymin) * 0.05
        ax.set_ylim(ymin - marg, ymax + marg)
        ax.yaxis.set_major_locator(ticker.AutoLocator())
        ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.2f'))
        
        # Legendas e t√≠tulo
        ax.set_xlabel('Dias (√≠ndice)')
        ax.set_ylabel('Pre√ßo (R$)')
        ax.set_title(
            f'{empresa} - TCN Rolling Forecast: {seq_length} dias ‚Üí 3 √† frente\n'
            f'MAE: {mae:.4f} | RMSE: {rmse:.4f}'
        )
        ax.legend()
        
        plt.tight_layout()
        
        # Salvar primeiro gr√°fico (bolinhas)
        filename_dots = f'{empresa}_tcn_rolling_{seq_length}dias_bolinhas.png'
        plt.savefig(filename_dots, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"‚úÖ Gr√°fico salvo: '{filename_dots}'")
        print("=" * 80)
    
    print(f"\nüéâ Todos os testes para {empresa} conclu√≠dos!")
    print("Gr√°ficos salvos:")
    for seq_length in seq_lengths_to_test:
        print(f"  üìç {empresa}_tcn_rolling_{seq_length}dias_bolinhas.png")
    
    # Gerar tabela Excel com m√©dias a cada 3 dias
    print(f"\nüìä Gerando tabela Excel com m√©dias a cada 3 dias para {empresa}...")
    
    # Criar uma data base hipot√©tica (1 de mar√ßo de 2025)
    data_base = datetime(2025, 3, 1)
    
    # Criar o arquivo Excel com m√∫ltiplas abas
    excel_filename = f'{empresa}_tcn_previsoes_medias_3dias.xlsx'
    
    with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:
        
        for seq_length in seq_lengths_to_test:
            print(f"  üìã Processando aba: {seq_length} dias...")
            
            # Obter dados deste seq_length
            predictions = all_results[seq_length]['predictions']
            real_vals = all_results[seq_length]['real_vals']
            mae = all_results[seq_length]['mae']
            rmse = all_results[seq_length]['rmse']
            
            # Calcular quantos grupos de 3 dias temos
            n_predictions = len(predictions)
            n_groups = n_predictions // 3  # grupos completos de 3
            
            # Listas para armazenar os resultados
            periodos = []
            medias_previsto = []
            medias_real = []
            diferencas_abs = []
            diferencas_perc = []
            
            for i in range(n_groups):
                # √çndices para o grupo atual (3 dias)
                start_idx = i * 3
                end_idx = start_idx + 3
                
                # Datas do per√≠odo
                data_inicio = data_base + timedelta(days=start_idx)
                data_fim = data_base + timedelta(days=end_idx - 1)
                periodo = f"{data_inicio.strftime('%d/%m/%y')}-{data_fim.strftime('%d/%m/%y')}"
                
                # Calcular m√©dias do per√≠odo
                media_prev = np.mean(predictions[start_idx:end_idx])
                media_real = np.mean(real_vals[start_idx:end_idx])
                
                # Calcular diferen√ßas
                diff_abs = abs(media_prev - media_real)
                diff_perc = (diff_abs / media_real) * 100 if media_real != 0 else 0
                
                # Armazenar resultados
                periodos.append(periodo)
                medias_previsto.append(media_prev)
                medias_real.append(media_real)
                diferencas_abs.append(diff_abs)
                diferencas_perc.append(diff_perc)
            
            # Criar DataFrame para esta aba
            df_seq = pd.DataFrame({
                'Per√≠odo': periodos,
                'M√©dia Previsto (R$)': medias_previsto,
                'M√©dia Real (R$)': medias_real,
                'Diferen√ßa Absoluta (R$)': diferencas_abs,
                'Diferen√ßa Percentual (%)': diferencas_perc
            })
            
            # Formatar valores monet√°rios
            df_seq['M√©dia Previsto (R$)'] = df_seq['M√©dia Previsto (R$)'].round(2)
            df_seq['M√©dia Real (R$)'] = df_seq['M√©dia Real (R$)'].round(2)
            df_seq['Diferen√ßa Absoluta (R$)'] = df_seq['Diferen√ßa Absoluta (R$)'].round(2)
            df_seq['Diferen√ßa Percentual (%)'] = df_seq['Diferen√ßa Percentual (%)'].round(2)
            
            # Adicionar estat√≠sticas resumo
            estatisticas = pd.DataFrame({
                'M√©trica': ['MAE Geral', 'RMSE Geral', 'M√©dia Diff. Abs.', 'M√©dia Diff. %', 'Tempo (min)'],
                'Valor': [
                    f"{mae:.4f}",
                    f"{rmse:.4f}", 
                    f"{np.mean(diferencas_abs):.2f}",
                    f"{np.mean(diferencas_perc):.2f}%",
                    f"{all_results[seq_length]['total_time']/60:.1f}"
                ]
            })
            
            # Salvar na aba correspondente
            nome_aba = f"{seq_length}_dias"
            df_seq.to_excel(writer, sheet_name=nome_aba, index=False, startrow=0)
            
            # Adicionar estat√≠sticas embaixo
            estatisticas.to_excel(writer, sheet_name=nome_aba, index=False, 
                                startrow=len(df_seq) + 3)
            
            print(f"    ‚úÖ {len(df_seq)} per√≠odos de 3 dias processados")
    
    print(f"\nüìà Tabela Excel salva como: '{excel_filename}'")
    print(f"üìã Abas criadas: {', '.join([f'{s}_dias' for s in seq_lengths_to_test])}")
    print("\nüéØ Estrutura da tabela:")
    print("  ‚Ä¢ Per√≠odo: Data in√≠cio-fim (dd/mm/yy)")
    print("  ‚Ä¢ M√©dia Previsto: M√©dia dos 3 dias previstos")
    print("  ‚Ä¢ M√©dia Real: M√©dia dos 3 dias reais")
    print("  ‚Ä¢ Diferen√ßa Absoluta: |Previsto - Real|")
    print("  ‚Ä¢ Diferen√ßa Percentual: (Diff. Abs. / Real) * 100")
    print("  ‚Ä¢ Estat√≠sticas gerais no final de cada aba")
    print("=" * 100)
